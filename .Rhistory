fig_sentiment <- ggplot(data %>% filter(date > "1950-04-11"),aes(x=date,y=sentiment_EO, color = sentiment_EO)) + geom_point() +
geom_smooth(aes(x=date,y=sentiment_EO),method=lm, se=FALSE)
fig_sentiment
fig_sentiment_China <- ggplot(data %>% filter(country == "China"),aes(x=date,y=sentiment_EO, color = sentiment_EO)) + geom_point() +
geom_smooth(aes(x=date,y=sentiment_EO),method=lm, se=FALSE)
fig_sentiment_China
fig_Obama <- ggplot(data %>% filter(president == "Barack Obama"),aes(x=date,y=sentiment_EO, color = sentiment_EO)) + geom_point() +
geom_smooth(aes(x=date,y=sentiment_EO),method=lm, se=FALSE)
fig_Obama
fig_Obama <- ggplot(data %>% filter(president == "Barack Obama"),aes(x=date,y=sentiment_EO, color = sentiment_EO)) + geom_point() +
geom_smooth(aes(x=date,y=sentiment_EO),method=lm, se=FALSE) +
labs(title = "obama")
fig_Obama
# frequency of EO by president
presidents <- table(data$president)
presidents_df <- as.data.frame(presidents)
names(presidents_df)[1]="president"
presidents_df
library(quanteda.textmodels)
library(quanteda.textplots)
library(quanteda.dictionaries)
library(quanteda.corpora)
library(quanteda.tidy)
sentiment_corpus <- corpus(data,
docid_field =  "eo_number",
text_field = 'text')
head(summary(sentiment_corpus))
sentiment_corpus_tokens <- tokens(sentiment_corpus,
remove_punct = TRUE,
remove_numbers = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("english"))
collocations <- sentiment_corpus_tokens %>%
textstat_collocations(min_count = 250,
size = 2) %>%
filter(count >250)
sentiment_corpus_tokens <- tokens_compound(sentiment_corpus_tokens,
phrase(collocations$collocation))
sentiment_corpus_dfm<-dfm(sentiment_corpus_tokens)
sentiment_corpus_dfm_AFINN <- sentiment_corpus_dfm %>%
dfm(.,
dictionary = data_dictionary_AFINN)
emotion <- convert(sentiment_corpus_dfm_AFINN, to = "data.frame")
net_emotion_AFINN <- emotion$positive-emotion$negative
data <- cbind(data,net_emotion_AFINN)
?sentiment
library(RSentiment)
sentiment_df<-sentiment(text.var = data$text,
polarity_dt = lexicon::hash_sentiment_jockers_rinker,
n.before = 5,
n.after = 2)
sentiment_mean<-aggregate(sentiment_df[,4],list(sentiment_df$element_id),mean)
data <- cbind(data,sentiment_mean$sentiment)
data <-data %>% rename(sentiment_valence = V2)
fig_3 <- ggplot(data %>% filter(president == "Barack Obama"),aes(x=date,y=sentiment_valence, color = sentiment_valence)) + geom_point() +
geom_smooth(aes(x=date,y=sentiment_valence),method=lm, se=FALSE)
fig_3
plot.top10.time <- ggplot(country.long, aes(x=year, y=n, color = factor(country))) +
geom_line() +
facet_grid(rows = vars(reorder(country, -n)), scales = 'free') +
labs(title = 'Top 10 EOs counts over time (1950 -2021)',
y = '',
x = 'Years',
subtitle = paste0('n = ', nrow(eo.top10))
) +
theme(plot.subtitle=element_text(size=9, hjust=0, face="italic", color="black")) +
theme_bw() +
theme(legend.position = "none")
plot.top10.time
# with fixed
plot.top10.time <- ggplot(country.long, aes(x=year, y=n, color = factor(country))) +
geom_line() +
facet_grid(rows = vars(reorder(country, -n)), scales = 'fixed') +
labs(title = 'Top 10 EOs counts over time (1950 -2021)',
y = '',
x = 'Years',
subtitle = paste0('n = ', nrow(eo.top10))
) +
theme(plot.subtitle=element_text(size=9, hjust=0, face="italic", color="black")) +
theme_bw() +
theme(legend.position = "none")
plot.top10.time
plot.top10.sentiment <- ggplot(country.long, aes(x=year, y=sentiment_EO, color = factor(country))) +
geom_line() +
facet_grid(rows = vars(reorder(country, -sentiment_EO)), scales = 'fixed') +
labs(title = 'Top 10 EOs counts over time (1950 -2021)',
y = 'Sentiment',
x = 'Years',
subtitle = paste0('sentiment_EO = ', nrow(eo.top10))
) +
theme(plot.subtitle=element_text(size=9, hjust=0, face="italic", color="black")) +
theme_bw() +
theme(legend.position = "none")
plot.top10.sentiment
plot.top10.sentiment <- ggplot(country.long, aes(x=year, y=sentiment_EO, color = factor(country))) +
geom_line() +
facet_grid(rows = vars(reorder(country, -sentiment_EO)), scales = 'fixed') +
labs(title = 'Top 10 EOs counts over time (1950 -2021)',
y = 'Sentiment',
x = 'Years',
subtitle = paste0('sentiment_EO = ', nrow(eo.top10))
) +
theme(plot.subtitle=element_text(size=9, hjust=0, face="italic", color="black")) +
theme_bw() +
theme(legend.position = "none")
plot.top10.sentiment
plot.top10.sentiment <- ggplot(data, aes(x=year, y=sentiment_EO, color = factor(country))) +
geom_line() +
facet_grid(rows = vars(reorder(country, -sentiment_EO)), scales = 'fixed') +
labs(title = 'Top 10 EOs counts over time (1950 -2021)',
y = 'Sentiment',
x = 'Years',
subtitle = paste0('sentiment_EO = ', nrow(eo.top10))
) +
theme(plot.subtitle=element_text(size=9, hjust=0, face="italic", color="black")) +
theme_bw() +
theme(legend.position = "none")
plot.top10.sentiment
glimpse(data)
ggplot(data, aes(x=date, y=sentiment_EO)) +
geom_line()
ggplot(data, aes(x=date, y=sentiment_EO)) +
geom_line() +
facet_grid(~ country)
ggplot(data, aes(x=date, y=sentiment_EO)) +
geom_line() +
facet_grid(. ~ country)
ggplot(data, aes(x=date, y=sentiment_EO)) +
geom_line() +
facet_grid(rows = vare(country))
ggplot(data, aes(x=date, y=sentiment_EO)) +
geom_line() +
facet_grid(rows = vars(country))
glimpse(country.long)
test_data <- data %>% group_by(country) %>% summarise(n = n())
data %>% group_by(country) %>% summarise(n = n(), min_rank(n))
?corpus
?tokens_lookup
data_dictionary_newsmap_en
head(eo.corpus)
glimpse(eo.corpus)
eo.corpus <- corpus(data,
docid_field =  "eo_number",
text_field = 'text')
head(summary(eo.corpus))
?gfm
?dfm
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
data <- fread('./data/executive_orders_cleaned.csv')
eo.corpus <- corpus(data,
docid_field =  "eo_number",
text_field = 'text')
head(summary(eo.corpus))
# set some dictionaries for later
month <- c("January", "February", "March", "April", "May", "June","July", "August", "September", "October", "November", "December")
day <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday","Sunday")
USA <- c("States", "Sec", "United","Act","Secretary","Council","State","Department","General","Section","Management","America","Committee","American","Americans","Washington")
# create tokens
eo.tokens <- tokens(eo.corpus,
remove_punct = TRUE,
remove_numbers = TRUE,
remove_symbols = TRUE) %>%
tokens_remove(c(stopwords("english"),
month,
day,
USA))
?tokens
eo.tokens
str(eo.tokens)
# Document-feature matrix
dfmat_label <- dfm(eo.label, tolower = FALSE)
dfmat_feat <- dfm(eo.tokens, tolower = FALSE)
# create tokens
eo.tokens <- tokens(eo.corpus,
remove_punct = TRUE,
remove_numbers = TRUE,
remove_symbols = TRUE) %>%
tokens_remove(c(stopwords("english"),
month,
day,
USA))
# create labels
eo.label <- tokens_lookup(eo.tokens,
dictionary = data_dictionary_newsmap_en,
levels = 3) # level 3 stands for countries
# Document-feature matrix
dfmat_label <- dfm(eo.label, tolower = FALSE)
dfmat_feat <- dfm(eo.tokens, tolower = FALSE)
dfmat_feat_select <- dfm_select(dfmat_feat, pattern = "^[A-Z][A-Za-z0-9]+",
valuetype = "regex", case_insensitive = FALSE) %>%
dfm_trim(min_termfreq = 10)
?tokens_lookup
?dfm
dfmat_feat_select <- dfm_select(dfmat_feat, pattern = "^[A-Z][A-Za-z0-9]+",
valuetype = "regex", case_insensitive = FALSE) %>%
dfm_trim(min_termfreq = 10)
?dfm_select
?dfm
?dfm_select
?ntoken
?tmod
?tmod_nm
??tmod_nm
library(newsmap)
?tmod_nm
?textmodel_newsmap()
e individual countries
coef(tmod_nm,n=15)[c("US","CN","IQ", "IN")]
# predict and cluster country labels on our documents
dfmat_label <- dfm(eo.label, tolower = FALSE)
dfmat_feat <- dfm(eo.tokens, tolower = FALSE)
# select
dfmat_feat_select <- dfm_select(dfmat_feat, pattern = "^[A-Z][A-Za-z0-9]+",
valuetype = "regex", case_insensitive = FALSE) %>%
dfm_trim(min_termfreq = 10)
tmod_nm <- textmodel_newsmap(dfmat_feat_select, y = dfmat_label)
summary(tmod_nm)
glimpse(tmod_nm)
# check which coefficients are associated to the individual countries
coef(tmod_nm,n=15)[c("US","CN","IQ", "IN")]
# predict and cluster country labels on our documents
pred_nm <- predict(tmod_nm)
count <-table(pred_nm)
count
?predict
?coef
count <-table(pred_nm)
count
dat_country <- as.data.frame(count, stringsAsFactors = FALSE)
dat_country
dat_country <- dat_country[order(-dat_country$Freq),]
dat_country
colnames(dat_country) <- c("id", "frequency")
world_map <- map_data(map = "world")
world_map$region <- iso.alpha(world_map$region) # convert country name to ISO code
?map_data
world_map
?iso.alpha
plot.map <- ggplot(dat_country, aes(map_id = id)) +
geom_map(aes(fill = frequency), map = world_map) +
expand_limits(x = world_map$long, y = world_map$lat) +
scale_fill_continuous(name = "Frequency") +
theme_void() +
coord_fixed() +
scale_fill_gradient(low="#56B1F7", high="#ff0000") +
labs(title = 'Frequency of countries (1950 -2021)',
subtitle = paste0('n = ', nrow(data)))
plot.map
plot.map
plot.map <- ggplot(dat_country, aes(map_id = id)) +
geom_map(aes(fill = frequency), map = world_map) +
expand_limits(x = world_map$long, y = world_map$lat) +
scale_fill_continuous(name = "Frequency") +
theme_void() +
coord_fixed() +
scale_fill_gradientn(colors=c("#56B1F7","yellow","orange","#ff0000")) +
labs(title = 'Frequency of countries (1950 -2021)',
subtitle = paste0('n = ', nrow(data)))
plot.map
plot.map <- ggplot(dat_country, aes(map_id = id)) +
geom_map(aes(fill = frequency), map = world_map) +
expand_limits(x = world_map$long, y = world_map$lat) +
scale_fill_continuous(name = "Frequency") +
theme_void() +
coord_fixed() +
scale_fill_gradientn(colors=c("#56B1F7","green","yellow","orange","#ff0000")) +
labs(title = 'Frequency of countries (1950 -2021)',
subtitle = paste0('n = ', nrow(data)))
plot.map
ggplot(dat_country, aes(Freq)) + geom_histogram()
ggplot(dat_country, aes(frequency) + geom_histogram()
ggplot(dat_country, aes(frequency)) +
geom_histogram()
ggplot(dat_country, aes(frequency)) +
geom_histogram()
ggplot(dat_country, aes(frequency)) +
geom_histogram(binwidth = 10)
ggplot(dat_country, aes(frequency)) +
geom_histogram(binwidth = 5)
ggplot(dat_country, aes(frequency)) +
geom_histogram(binwidth = 1) + lims(x = c(0, 100))
plot.map <- ggplot(dat_country, aes(map_id = id)) +
geom_map(aes(fill = frequency), map = world_map) +
expand_limits(x = world_map$long, y = world_map$lat) +
scale_fill_continuous(name = "Frequency") +
theme_void() +
coord_fixed() +
scale_fill_gradientn(colors=c("#56B1F7","green","yellow","orange","#ff0000")) +
scale_fill_continuous(breaks = c(5, 25, 100, 200, 400, 700))
labs(title = 'Frequency of countries (1950 -2021)',
subtitle = paste0('n = ', nrow(data)))
plot.map
plot.map <- ggplot(dat_country, aes(map_id = id)) +
geom_map(aes(fill = frequency), map = world_map) +
expand_limits(x = world_map$long, y = world_map$lat) +
scale_fill_continuous(name = "Frequency") +
theme_void() +
coord_fixed() +
scale_fill_gradientn(colors=c("#56B1F7","green","yellow","orange","#ff0000"), breaks = c(5, 25, 100, 200, 400, 700)) +
labs(title = 'Frequency of countries (1950 -2021)',
subtitle = paste0('n = ', nrow(data)))
plot.map
plot.map <- ggplot(dat_country, aes(map_id = id)) +
geom_map(aes(fill = frequency), map = world_map) +
expand_limits(x = world_map$long, y = world_map$lat) +
scale_fill_continuous(name = "Frequency") +
theme_void() +
coord_fixed() +
scale_fill_gradientn(colors=c("#56B1F7","green","yellow","orange","#ff0000"), breaks = c(5, 25, 100, 200, 400)) +
labs(title = 'Frequency of countries (1950 -2021)',
subtitle = paste0('n = ', nrow(data)))
plot.map
plot.map <- ggplot(dat_country, aes(map_id = id)) +
geom_map(aes(fill = frequency), map = world_map) +
expand_limits(x = world_map$long, y = world_map$lat) +
scale_fill_continuous(name = "Frequency") +
theme_void() +
coord_fixed() +
scale_fill_gradientn(colors=c("#56B1F7","green","yellow","orange","#ff0000"), values = scales::rescale(c(5, 25, 100, 200, 400))) +
labs(title = 'Frequency of countries (1950 -2021)',
subtitle = paste0('n = ', nrow(data)))
plot.map
ggplot(dat_country, aes(frequency)) +
geom_histogram(binwidth = 1))
ggplot(dat_country, aes(frequency)) +
geom_histogram(binwidth = 1)
ggplot(dat_country, aes(frequency)) +
geom_histogram(binwidth = 2)
?countrycode
count
top10 <- dat_country[1:10, ]
top10$country <- countrycode(top10$id, origin = 'iso2c', destination = 'country.name')
top10 <- top10[order(-top10$frequency),]
rownames(top10) <- NULL
# add country to dataframe
data$iso <- pred_nm
data$country <- countrycode(pred_nm, origin = 'iso2c', destination = 'country.name')
# get EOs only for top 10 countries
target <- top10$country
eo.top10 <- filter(data, country %in% target)
nrow(eo.top10)/nrow(data) # account for the majority
# plot frequency of top 10 countries
plot.top10 <- ggplot(top10, aes(x = frequency, y = reorder(country, frequency))) +
geom_bar(stat = 'identity') +
labs(title = 'Top 10 Frequency of countries (1950 -2021)',
y = '',
x = 'number of EOs',
subtitle = paste0('n = ', nrow(eo.top10))
) +
theme(plot.subtitle=element_text(size=9, hjust=0, face="italic", color="black"))
plot.top10
top10 <- dat_country[1:10, ]
top10
top10 <- top10[order(-top10$frequency),]
top10
top10 <- dat_country[1:10, ]
top10
top10$country <- countrycode(top10$id, origin = 'iso2c', destination = 'country.name')
top10 <- top10[order(-top10$frequency),]
rownames(top10) <- NULL
top10
?countrycode
data$iso <- pred_nm
data$country <- countrycode(pred_nm, origin = 'iso2c', destination = 'country.name')
data$iso <- pred_nm
data
glimpse(data)
pred_nm <- predict(tmod_nm)
pred_nm
?dfm_select
pred_nm <- predict(tmod_nm)
count <-table(pred_nm)
count
dat_country <- as.data.frame(count, stringsAsFactors = FALSE)
dat_country <- dat_country[order(-dat_country$Freq),]
dat_country
# plot the newsmap
dat_country <- as.data.frame(count, stringsAsFactors = FALSE)
dat_country <- dat_country[order(dat_country$Freq),]
dat_country
op10 <- dat_country[1:10, ]
top10$country <- countrycode(top10$id, origin = 'iso2c', destination = 'country.name')
top10 <- top10[order(-top10$frequency),]
rownames(top10) <- NULL
# add country to dataframe
data$iso <- pred_nm
data$country <- countrycode(pred_nm, origin = 'iso2c', destination = 'country.name')
# get EOs only for top 10 countries
target <- top10$country
eo.top10 <- filter(data, country %in% target)
nrow(eo.top10)/nrow(data) # account for the majority
# plot frequency of top 10 countries
plot.top10 <- ggplot(top10, aes(x = frequency, y = reorder(country, frequency))) +
geom_bar(stat = 'identity') +
labs(title = 'Top 10 Frequency of countries (1950 -2021)',
y = '',
x = 'number of EOs',
subtitle = paste0('n = ', nrow(eo.top10))
) +
theme(plot.subtitle=element_text(size=9, hjust=0, face="italic", color="black"))
plot.top10
# plot counts over times
eo.top10$year <- year(eo.top10$date)
# count EOs per year and country
country.long <- eo.top10 %>% count(year, country)
# plot top 10 over time
plot.top10.time <- ggplot(country.long, aes(x=year, y=n, color = factor(country))) +
geom_line() +
facet_grid(rows = vars(reorder(country, -n)), scales = 'free') +
labs(title = 'Top 10 EOs counts over time (1950 -2021)',
y = '',
x = 'Years',
subtitle = paste0('n = ', nrow(eo.top10))
) +
theme(plot.subtitle=element_text(size=9, hjust=0, face="italic", color="black")) +
theme_bw() +
theme(legend.position = "none")
plot.top10.time
# with fixed
plot.top10.time <- ggplot(country.long, aes(x=year, y=n, color = factor(country))) +
geom_line() +
facet_grid(rows = vars(reorder(country, -n)), scales = 'fixed') +
labs(title = 'Top 10 EOs counts over time (1950 -2021)',
y = '',
x = 'Years',
subtitle = paste0('n = ', nrow(eo.top10))
) +
theme(plot.subtitle=element_text(size=9, hjust=0, face="italic", color="black")) +
theme_bw() +
theme(legend.position = "none")
plot.top10.time
View(data)
library(here)
library(readtext)
library(quanteda)
library(stringr)
library(dplyr)
library(newsmap)
library(sentimentr)
library(data.table)
library(tidyr)
library(maps)
library(countrycode)
library(ggplot2)
# Setup----
#===================#
rm(list=ls())
# set wd to where the source file is
# make sure you have the datafiles in a /data/ folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
data <- fread('./data/executive_orders_withcountry.csv')
library(syuzhet)
library(tidyverse)
library(lubridate)
library(plotly)
library(tibble)
data[,"sentiment_syuzhet"]<-NA
data$sentiment_syuzhet <- get_sentiment(data$text)
fig_sentiment <- ggplot(data %>% filter(date > "1950-04-11"),aes(x=date,y=sentiment_syuzhet, color = sentiment_syuzhet)) + geom_point() +
geom_smooth(aes(x=date,y=sentiment_syuzhet),method=lm, se=FALSE)
fig_sentiment
fig_sentiment_China <- ggplot(data %>% filter(country == "China"),aes(x=date,y=sentiment_syuzhet, color = sentiment_syuzhet)) + geom_point() +
geom_smooth(aes(x=date,y=sentiment_syuzhet),method=lm, se=FALSE)
fig_sentiment_China
fig_Obama <- ggplot(data %>% filter(president == "Barack Obama"),aes(x=date,y=sentiment_syuzhet, color = sentiment_syuzhet)) + geom_point() +
geom_smooth(aes(x=date,y=sentiment_syuzhet),method=lm, se=FALSE)
fig_Obama
sentiment_df<-sentiment_by(text.var = data$text,
polarity_dt = lexicon::hash_sentiment_jockers_rinker,
n.before = 5,
n.after = 2)
glimpse(sentiment_df)
summary(sentiment_df$ave_sentiment)
data <- cbind(data,sentiment_df$ave_sentiment)
data <-data %>% rename(sentiment_valence = V2)
fig_3 <- ggplot(data %>% filter(president == "Barack Obama"),aes(x=date,y=sentiment_valence, color = sentiment_valence)) + geom_point() +
geom_smooth(aes(x=date,y=sentiment_valence),method=lm, se=FALSE)
fig_3
rm(sentiment_df)
library(quanteda.textmodels)
library(quanteda.textplots)
library(quanteda.dictionaries)
library(quanteda.corpora)
library(quanteda.tidy)
sentiment_corpus <- corpus(data,
docid_field =  "eo_number",
text_field = 'text')
head(summary(sentiment_corpus))
sentiment_corpus_tokens <- tokens(sentiment_corpus,
remove_punct = TRUE,
remove_numbers = TRUE,
remove_symbols = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("english"))
collocations <- sentiment_corpus_tokens %>%
textstat_collocations(min_count = 250,
size = 2) %>%
filter(count >250)
sentiment_corpus_tokens <- tokens_compound(sentiment_corpus_tokens,
phrase(collocations$collocation))
sentiment_corpus_dfm<-dfm(sentiment_corpus_tokens)
sentiment_corpus_dfm_AFINN <- sentiment_corpus_dfm %>%
dfm(.,
dictionary = data_dictionary_AFINN)
emotion <- convert(sentiment_corpus_dfm_AFINN, to = "data.frame")
net_emotion_AFINN <- emotion$positive-emotion$negative
data <- cbind(data,net_emotion_AFINN)
rm(sentiment_corpus_dfm, sentiment_corpus_dfm_AFINN, sentiment_corpus_tokens,
net_emotion_AFINN, sentiment_corpus, emotion, collocations)
View(data)
